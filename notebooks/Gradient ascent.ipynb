{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "from bokeh.plotting import figure, show\n",
    "from bokeh.io import output_notebook\n",
    "\n",
    "from keras.layers import Conv2D, MaxPool2D, Activation, Dense, Input, Flatten, BatchNormalization, Dropout\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import Sequence\n",
    "import keras.backend as K\n",
    "\n",
    "from scipy.io import wavfile\n",
    "from scipy.fftpack import fft\n",
    "\n",
    "import time\n",
    "\n",
    "from pylab import rcParams\n",
    "\n",
    "#%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './checkpoints_RAW/'\n",
    "\n",
    "def find_best_checkpoint(prev_chkpts):\n",
    "    best_ratio = np.inf\n",
    "    best_chkpt = ''\n",
    "    best_epoch = 0\n",
    "    for chkpt in prev_chkpts:\n",
    "        epoch = int(chkpt[8:11])\n",
    "        ratio = float(chkpt[12:19])\n",
    "        \n",
    "        if ratio < best_ratio:\n",
    "            best_ratio = ratio\n",
    "            best_chkpt = chkpt\n",
    "            best_epoch = epoch\n",
    "    print('\\n starting from model {} \\n'.format(best_chkpt))\n",
    "    return best_chkpt, best_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_checkpoints = os.listdir(checkpoint_dir)\n",
    "best_checkpoint, best_epoch = find_best_checkpoint(previous_checkpoints)\n",
    "#model.load_weights(checkpoint_dir + best_checkpoint)\n",
    "model = keras.models.load_model(checkpoint_dir + best_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()\n",
    "\n",
    "# this is the placeholder for the input images\n",
    "input_model = model.input\n",
    "song_lenght = 465984"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "    # utility function to normalize a tensor by its L2 norm\n",
    "    return x / (K.sqrt(K.mean(K.square(x))) + K.epsilon())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient ascent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we only scan through the first 200 filters\n",
    "# but there are actually 512 of them\n",
    "\n",
    "\n",
    "annotations = pd.read_csv('../data/MagnaTagATune/annotation_reduced_50.csv', sep='\\t')\n",
    "\n",
    "start_time = time.time()\n",
    "# we build a loss function that maximizes the activation\n",
    "# of the nth filter of the layer considered\n",
    "output = model.output\n",
    "des = [1.3541062e-03, 7.7507906e-07, 1.6718840e-03, 1.0865202e-04,\n",
    "    1.1998077e-02, 2.5674235e-03, 2.2245251e-07, 1.4077784e-05,\n",
    "    4.3773609e-03, 7.8408426e-05, 1.7920894e-03, 1.3590881e-03,\n",
    "    1.3103581e-04, 1.8276019e-03, 5.2062300e-04, 3.5621008e-05,\n",
    "    9.0753223e-05, 2.6076185e-04, 5.5475216e-06, 4.7324235e-03,\n",
    "    1.2859477e-01, 3.7038975e-04, 1.7310167e-02, 5.1931955e-05,\n",
    "    1.3747557e-04, 1.3612196e-05, 1.1201203e-02, 1.0006372e-04,\n",
    "    8.4008680e-06, 2.4455197e-01, 2.0188638e-05, 1.1828544e-03,\n",
    "    2.0245390e-02, 4.9718535e-03, 4.1305888e-02, 1.2869519e-02,\n",
    "    1.3738136e-03, 5.1308460e-05, 6.5179415e-02, 1.9230554e-01,\n",
    "    5.4180467e-01, 1.6391259e-02, 2.4036810e-01, 6.3938588e-02,\n",
    "    2.3827245e-03, 8.5998207e-01, 1.3587170e-04, 4.1804422e-02,\n",
    "    1.2138104e-03, 2.0679317e-03]\n",
    "print('Finding input minimizing label: {}\\n'.format(des))\n",
    "desired_output = K.variable(np.array(des))\n",
    "loss = K.mean(K.pow(output - desired_output,2))\n",
    "\n",
    "# we compute the gradient of the input picture wrt this loss\n",
    "grads = K.gradients(loss, input_model)[0]\n",
    "# normalization trick: we normalize the gradient\n",
    "grads = normalize(grads)\n",
    "# this function returns the loss and grads given the input picture\n",
    "iterate = K.function([input_model], [loss, grads])\n",
    "# step size for gradient ascent\n",
    "step = 1000.\n",
    "\n",
    "# we start from a gray image with some random noise\n",
    "input_song_data = np.float32(np.random.randint(-30000,30000, size = (1, song_lenght, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    print(i)\n",
    "    loss_value, grads_value = iterate([input_song_data])\n",
    "    print(i)\n",
    "    input_song_data -= grads_value * step\n",
    "    print('Current loss value:', loss_value)\n",
    "end_time = time.time()\n",
    "wavfile.write('sound.wav', 16000, input_song_data[0,:,0])\n",
    "print('processed in {}s'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_song_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

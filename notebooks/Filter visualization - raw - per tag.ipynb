{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emanuele.dallalonga/miniconda3/envs/musictagger/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "\n",
    "\n",
    "from bokeh.plotting import figure, show\n",
    "from bokeh.io import output_notebook\n",
    "\n",
    "from keras.layers import Conv2D, MaxPool2D, Activation, Dense, Input, Flatten, BatchNormalization, Dropout\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import Sequence\n",
    "import keras.backend as K\n",
    "\n",
    "from scipy.io import wavfile\n",
    "from scipy.fftpack import fft\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import time\n",
    "\n",
    "from pylab import rcParams\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './checkpoints_RAW/'\n",
    "\n",
    "def find_best_checkpoint(prev_chkpts):\n",
    "    best_ratio = np.inf\n",
    "    best_chkpt = ''\n",
    "    best_epoch = 0\n",
    "    for chkpt in prev_chkpts:\n",
    "        epoch = int(chkpt[8:11])\n",
    "        ratio = float(chkpt[12:19])\n",
    "        \n",
    "        if ratio < best_ratio:\n",
    "            best_ratio = ratio\n",
    "            best_chkpt = chkpt\n",
    "            best_epoch = epoch\n",
    "    print('\\n starting from model {} \\n'.format(best_chkpt))\n",
    "    return best_chkpt, best_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " starting from model weights-031-0.13050.hdf5 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emanuele.dallalonga/miniconda3/envs/musictagger/lib/python3.6/site-packages/keras/models.py:282: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "previous_checkpoints = os.listdir(checkpoint_dir)\n",
    "best_checkpoint, best_epoch = find_best_checkpoint(previous_checkpoints)\n",
    "#model.load_weights(checkpoint_dir + best_checkpoint)\n",
    "model = keras.models.load_model(checkpoint_dir + best_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 155328, 128)       512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 155328, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 155328, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 155328, 128)       49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 155328, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 155328, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 51776, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 51776, 256)        98560     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 51776, 256)        1024      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 51776, 256)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 17258, 256)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 17258, 256)        196864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 17258, 256)        1024      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 17258, 256)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 5752, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 5752, 256)         196864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 5752, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 5752, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 1917, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 1917, 256)         196864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 1917, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 1917, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 639, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 639, 256)          196864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 639, 256)          1024      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 639, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 213, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 213, 256)          196864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 213, 256)          1024      \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 213, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 71, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 71, 512)           393728    \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 71, 512)           2048      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 71, 512)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 23, 512)           0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 23, 512)           0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 11776)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                588850    \n",
      "=================================================================\n",
      "Total params: 2,124,466\n",
      "Trainable params: 2,119,858\n",
      "Non-trainable params: 4,608\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation_1': <keras.layers.core.Activation at 0x7f43c41c1ac8>,\n",
       " 'activation_2': <keras.layers.core.Activation at 0x7f448a288cc0>,\n",
       " 'activation_3': <keras.layers.core.Activation at 0x7f43c3d2d128>,\n",
       " 'activation_4': <keras.layers.core.Activation at 0x7f43c3c4eeb8>,\n",
       " 'activation_5': <keras.layers.core.Activation at 0x7f43c3ab80b8>,\n",
       " 'activation_6': <keras.layers.core.Activation at 0x7f43c3940940>,\n",
       " 'activation_7': <keras.layers.core.Activation at 0x7f43c389fb38>,\n",
       " 'activation_8': <keras.layers.core.Activation at 0x7f43c3764b00>,\n",
       " 'activation_9': <keras.layers.core.Activation at 0x7f43c3629a90>}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is the placeholder for the input images\n",
    "input_model = model.input\n",
    "song_lenght = 465984\n",
    "\n",
    "# get the symbolic outputs of each \"key\" layer (we gave them unique names).\n",
    "layer_dict = dict([(layer.name, layer) for layer in model.layers[0:] if 'activation' in layer.name])\n",
    "layer_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "    # utility function to normalize a tensor by its L2 norm\n",
    "    return x / (K.sqrt(K.mean(K.square(x))) + K.epsilon())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete Train set size: 22400\n",
      "Test set size: 3460 \n",
      "\n",
      "Train set size: 20480\n",
      "Validation set size: 1920 \n",
      "\n",
      "X dimension: 465984\n",
      "Y dimension: 50 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "annotations_path = '../data/MagnaTagATune/annotation_reduced_50.csv'\n",
    "dataset_dir = '../data/MagnaTagATune/rawwav_2/'\n",
    "\n",
    "annotations = pd.read_csv(annotations_path, sep='\\t')\n",
    "\n",
    "\n",
    "tot_t_size = 0.866203\n",
    "tot_train_set, test_set = train_test_split(annotations, train_size=tot_t_size, test_size=(1-tot_t_size), random_state=42) \n",
    "\n",
    "print(\"Complete Train set size: {}\".format(tot_train_set.shape[0]))\n",
    "print(\"Test set size: {} \\n\".format(test_set.shape[0]))\n",
    "\n",
    "t_size = 0.91429\n",
    "train_set, val_set = train_test_split(tot_train_set, train_size=t_size, test_size=(1-t_size), random_state=42) \n",
    "\n",
    "print(\"Train set size: {}\".format(train_set.shape[0]))\n",
    "print(\"Validation set size: {} \\n\".format(val_set.shape[0]))\n",
    "\n",
    "train_set_paths = train_set['mp3_path'].values\n",
    "train_set_labels = train_set.drop(columns=['mp3_path','Unnamed: 0']).values\n",
    "\n",
    "y_dimension = train_set_labels.shape[1]\n",
    "_, data = wavfile.read( dataset_dir + annotations['mp3_path'][0][:-3]+ 'wav')\n",
    "x_dimension = len(data)\n",
    "\n",
    "print(\"X dimension: {}\\nY dimension: {} \\n\".format(x_dimension, y_dimension))\n",
    "\n",
    "   \n",
    "val_set_paths = val_set['mp3_path'].values\n",
    "val_set_labels = val_set.drop(columns=['mp3_path','Unnamed: 0']).values\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MagnaTagATuneSequence(Sequence):\n",
    "\n",
    "    def __init__(self, train_set_paths, train_set_labels, batch_size):\n",
    "        self.paths, self.y = train_set_paths, train_set_labels\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.paths) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x_paths = self.paths[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_x = []\n",
    "        for value in batch_x_paths:\n",
    "            path = dataset_dir + value[:-3]+'wav'\n",
    "            _, data = wavfile.read(path)\n",
    "            batch_x.append(data)\n",
    "        batch_x = np.array(batch_x)[:,:,np.newaxis]        \n",
    "        return (batch_x,batch_y)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "640/640 [==============================] - 403s 629ms/step\n"
     ]
    }
   ],
   "source": [
    "n_gpus = 4\n",
    "parallel_model = keras.utils.multi_gpu_model(model, gpus=n_gpus)\n",
    "\n",
    "y_pred = parallel_model.predict_generator(MagnaTagATuneSequence(train_set_paths,train_set_labels,32), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pk\n",
    "pk.dump(y_pred, open('y_train_pred_raw.p', 'wb' ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_layers = dict()\n",
    "for layer in conv_layers:\n",
    "    intermediate_layer_model = keras.Model(inputs=model.input,\n",
    "                                 outputs=model.get_layer(layer).output)\n",
    "    outputs_layers[layer] = intermediate_layer_model.predict(song[np.newaxis,:,np.newaxis])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_idx = 0\n",
    "outputs = outputs_layers[conv_layers[layer_idx]][0,:,:]\n",
    "\n",
    "print('Filters shape: {}'.format(outputs.shape))\n",
    "\n",
    "# Build fft for each output of the filter and plot everything\n",
    "spectrum = (np.array([np.abs(np.fft.rfft(output)[0:nUniquePts]) for output in outputs.T]).T)\n",
    "plt.figure(figsize=(10,100))\n",
    "plt.imshow(spectrum.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we only scan through the first 200 filters\n",
    "# but there are actually 512 of them\n",
    "\n",
    "\n",
    "annotations = pd.read_csv('../data/MagnaTagATune/annotation_reduced_50.csv', sep='\\t')\n",
    "\n",
    "for lbl_index in range(len(annotations.columns.values[1:-1])):\n",
    "    print('Finding input minimizing label: {}'.format(annotations.columns.values[1:-1][lbl_index]))\n",
    "    start_time = time.time()\n",
    "    # we build a loss function that maximizes the activation\n",
    "    # of the nth filter of the layer considered\n",
    "    output = model.output\n",
    "    des = np.zeros(50)\n",
    "    des[lbl_index] = 1\n",
    "    desired_output = K.variable(np.array(des))\n",
    "    loss = K.mean(K.pow(output - desired_output,2))\n",
    "\n",
    "    # we compute the gradient of the input picture wrt this loss\n",
    "    grads = K.gradients(loss, input_model)[0]\n",
    "    # normalization trick: we normalize the gradient\n",
    "    grads = normalize(grads)\n",
    "    # this function returns the loss and grads given the input picture\n",
    "    iterate = K.function([input_model], [loss, grads])\n",
    "    # step size for gradient ascent\n",
    "    step = 1000.\n",
    "\n",
    "    # we start from a gray image with some random noise\n",
    "    input_song_data = np.float32(np.random.randint(-30000,30000, size = (1, song_lenght, 1)))\n",
    "    \n",
    "    for i in range(20):\n",
    "        loss_value, grads_value = iterate([input_song_data])\n",
    "        input_song_data -= grads_value * step\n",
    "        print('Current loss value:', loss_value)\n",
    "    end_time = time.time()\n",
    "    wavfile.write('{}_sound.wav'.format(annotations.columns.values[1:-1][lbl_index]),sr, input_song_data[0,:,0])\n",
    "    print('processed in {}s'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(input_song_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(time_range, input_song_data[0,:,0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dir = './grad_ascent_songs/'\n",
    "S = []\n",
    "for file in os.listdir(file_dir):\n",
    "    sr, data = wavfile.read(file_dir + file)\n",
    "    S.append(data)\n",
    "S = np.array(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_song(song, sr):\n",
    "    time_interval = 1/sr\n",
    "    time_range = (np.arange(0, len(song))*time_interval)\n",
    "    plt.plot(time_range, song)\n",
    "    \n",
    "def plot_fft(song, sr):\n",
    "    n = len(song) \n",
    "    p = fft(song)\n",
    "    nUniquePts = int(np.ceil((n+1)/2.0))\n",
    "    p = p[0:nUniquePts]\n",
    "    p = np.abs(p)\n",
    "\n",
    "    if n % 2 > 0: # we've got odd number of points fft\n",
    "        p[1:len(p)] = p[1:len(p)] * 2\n",
    "    else:\n",
    "        p[1:len(p) -1] = p[1:len(p) - 1] * 2\n",
    "    \n",
    "    freqArray = np.arange(0, nUniquePts, 1.0) * (sr / n);\n",
    "    plt.plot(freqArray, p, color='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_song(S[0,:], 16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_fft(S[49,:], 16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_song(S[2,:], 16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_song(S[40,:], 16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.randint(-30000,30000, size = (1, song_lenght, 1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_song_data = (np.random.randint(-30000,30000, size = (1, song_lenght, 1)))\n",
    "input_song_data[0,:,0] = np.float(input_song_data[0,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "musictagger",
   "language": "python",
   "name": "musictagger"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import roc_auc_score, auc, roc_curve\n",
    "from sklearn.datasets import make_classification\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import Callback, EarlyStopping\n",
    "\n",
    "\n",
    "    \n",
    "def auc_roc(y_true, y_pred):\n",
    "    # any tensorflow metric\n",
    "    value, update_op = tf.metrics.auc(y_true, y_pred)\n",
    "\n",
    "    # find all variables created for this metric\n",
    "    metric_vars = [i for i in tf.local_variables() if 'auc_roc' in i.name.split('/')[1]]\n",
    "\n",
    "    # Add metric variables to GLOBAL_VARIABLES collection.\n",
    "    # They will be initialized for new session.\n",
    "    for v in metric_vars:\n",
    "        print(v)\n",
    "        tf.add_to_collection(tf.GraphKeys.GLOBAL_VARIABLES, v)\n",
    "    # force to update metric values\n",
    "    with tf.control_dependencies([update_op]):\n",
    "        value = tf.identity(value)\n",
    "        return value\n",
    "\n",
    "def auc_roc_ignorante(y_true, y_pred):\n",
    "    # any tensorflow metric\n",
    "    value, _ = tf.metrics.auc(y_true,y_pred)\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generation a small dataset\n",
    "N_all = 1000\n",
    "N_tr = int(0.7 * N_all)\n",
    "N_te = N_all - N_tr\n",
    "\n",
    "np.random.seed(0)\n",
    "x_dim = 50\n",
    "y_dim = 30\n",
    "X = np.random.rand(N_all,x_dim)\n",
    "y = np.random.randint(0,2,size=(N_all-1,y_dim))\n",
    "y_app = np.zeros(shape= (1,y_dim))\n",
    "y_app[0] = 1\n",
    "y = np.vstack((y,y_app))\n",
    "\n",
    "X_train, X_valid = X[:N_tr, :], X[N_tr:, :]\n",
    "y_train, y_valid = y[:N_tr, :], y[N_tr:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCallBack(keras.callbacks.Callback):\n",
    "    def __init__(self, callbacks,model):\n",
    "            super().__init__()\n",
    "            self.callback = callbacks\n",
    "            self.model = model\n",
    "            self.model_original = model\n",
    "            self.aucs = []\n",
    "\n",
    "    def on_epoch_begin(self,epoch,logs=None):\n",
    "            self.model = self.model_original\n",
    "            self.callback.on_epoch_begin(epoch, logs=logs)\n",
    "\n",
    "    def on_epoch_end(self,epoch,logs=None):\n",
    "            self.model = self.model_original\n",
    "            y_pred = self.model.predict(self.validation_data)\n",
    "            \n",
    "            self.callback.on_epoch_end(epoch, logs=logs)\n",
    "\n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "            self.model = self.model_original\n",
    "            self.callback.on_batch_end(batch, logs=logs)\n",
    "\n",
    "    def on_batch_begin(self, batch, logs=None):\n",
    "            self.model = self.model_original\n",
    "            self.callback.on_batch_begin(batch, logs=logs)\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "            self.model = self.model_original\n",
    "            self.callback.set_model(self.model)\n",
    "            self.callback.on_train_begin(logs=logs)\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "            self.model = self.model_original\n",
    "            self.callback.on_train_end(logs=logs)\n",
    "\n",
    "cbk_tb = keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=0, batch_size=batch_size, write_graph=True,\n",
    "                                         write_grads=False, write_images=False, embeddings_freq=0,\n",
    "                                         embeddings_layer_names=None, embeddings_metadata=None)\n",
    "\n",
    "cbk_es = keras.callbacks.EarlyStopping(monitor='val_loss', mode='max',\n",
    "                                          min_delta=min_improvement, patience=patience, verbose=1)\n",
    "\n",
    "cbk_mc = keras.callbacks.ModelCheckpoint(monitor='val_loss', mode='max', save_best_only=True, \n",
    "                                            filepath=checkpoint_dir+checkpoint_file_name, \n",
    "                                            verbose=1)\n",
    "\n",
    "cbk = MyCallBack(cbk_tb, model)\n",
    "cbk1 = MyCallBack(cbk_es, model)\n",
    "cbk2 = MyCallBack(cbk_mc, model)\n",
    "\n",
    "callbacks = [cbk,cbk1,cbk2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'metrics/auc_roc/auc/true_positives:0' shape=(200,) dtype=float32_ref>\n",
      "<tf.Variable 'metrics/auc_roc/auc/false_negatives:0' shape=(200,) dtype=float32_ref>\n",
      "<tf.Variable 'metrics/auc_roc/auc/true_negatives:0' shape=(200,) dtype=float32_ref>\n",
      "<tf.Variable 'metrics/auc_roc/auc/false_positives:0' shape=(200,) dtype=float32_ref>\n",
      "<tf.Variable 'metrics_1/auc_roc/auc/true_positives:0' shape=(200,) dtype=float32_ref>\n",
      "<tf.Variable 'metrics_1/auc_roc/auc/false_negatives:0' shape=(200,) dtype=float32_ref>\n",
      "<tf.Variable 'metrics_1/auc_roc/auc/true_negatives:0' shape=(200,) dtype=float32_ref>\n",
      "<tf.Variable 'metrics_1/auc_roc/auc/false_positives:0' shape=(200,) dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "# model & train\n",
    "model = Sequential()\n",
    "model.add(Dense(y_dim,input_shape=(X.shape[1],)))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy', auc_roc])\n",
    "\n",
    "my_callbacks = [EarlyStopping(monitor='auc_roc', patience=300, verbose=1, mode='max')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 0s 11us/step - loss: 0.7026 - acc: 0.5039 - auc_roc: 0.5003\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 0s 10us/step - loss: 0.7025 - acc: 0.5037 - auc_roc: 0.5004\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 0s 10us/step - loss: 0.7025 - acc: 0.5038 - auc_roc: 0.5006\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 0s 10us/step - loss: 0.7024 - acc: 0.5042 - auc_roc: 0.5007\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 0s 11us/step - loss: 0.7023 - acc: 0.5045 - auc_roc: 0.5009\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 0s 10us/step - loss: 0.7022 - acc: 0.5046 - auc_roc: 0.5010\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 0s 10us/step - loss: 0.7022 - acc: 0.5046 - auc_roc: 0.5011\n",
      "Epoch 8/20\n",
      "1000/1000 [==============================] - 0s 10us/step - loss: 0.7021 - acc: 0.5049 - auc_roc: 0.5013\n",
      "Epoch 9/20\n",
      "1000/1000 [==============================] - 0s 10us/step - loss: 0.7020 - acc: 0.5051 - auc_roc: 0.5014\n",
      "Epoch 10/20\n",
      "1000/1000 [==============================] - 0s 10us/step - loss: 0.7020 - acc: 0.5052 - auc_roc: 0.5015\n",
      "Epoch 11/20\n",
      "1000/1000 [==============================] - 0s 10us/step - loss: 0.7019 - acc: 0.5052 - auc_roc: 0.5017\n",
      "Epoch 12/20\n",
      "1000/1000 [==============================] - 0s 10us/step - loss: 0.7018 - acc: 0.5052 - auc_roc: 0.5018\n",
      "Epoch 13/20\n",
      "1000/1000 [==============================] - 0s 10us/step - loss: 0.7017 - acc: 0.5055 - auc_roc: 0.5019\n",
      "Epoch 14/20\n",
      "1000/1000 [==============================] - 0s 10us/step - loss: 0.7017 - acc: 0.5058 - auc_roc: 0.5021\n",
      "Epoch 15/20\n",
      "1000/1000 [==============================] - 0s 10us/step - loss: 0.7016 - acc: 0.5060 - auc_roc: 0.5022\n",
      "Epoch 16/20\n",
      "1000/1000 [==============================] - 0s 10us/step - loss: 0.7015 - acc: 0.5061 - auc_roc: 0.5023\n",
      "Epoch 17/20\n",
      "1000/1000 [==============================] - 0s 10us/step - loss: 0.7015 - acc: 0.5061 - auc_roc: 0.5024\n",
      "Epoch 18/20\n",
      "1000/1000 [==============================] - 0s 10us/step - loss: 0.7014 - acc: 0.5064 - auc_roc: 0.5026\n",
      "Epoch 19/20\n",
      "1000/1000 [==============================] - 0s 10us/step - loss: 0.7013 - acc: 0.5067 - auc_roc: 0.5027\n",
      "Epoch 20/20\n",
      "1000/1000 [==============================] - 0s 10us/step - loss: 0.7012 - acc: 0.5067 - auc_roc: 0.5028\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f703c61e710>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y,batch_size=len(X), epochs=20, verbose=1,callbacks=my_callbacks)\n",
    "\n",
    "# # or use independent valid set\n",
    "# model.fit(X_train, y_train,\n",
    "#           validation_data=(X_valid, y_valid),\n",
    "#           batch_size=32, nb_epoch=5, verbose=1,\n",
    "#           callbacks=my_callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.47728682930015354\n",
      "0.4710925496093367\n",
      "0.5237768576818482\n",
      "0.5193266883811297\n",
      "0.5193231378517482\n",
      "0.5344299108313664\n",
      "0.49582802651774927\n",
      "0.5495099003409388\n",
      "0.5488306767703163\n",
      "0.47643654233912114\n",
      "0.5437976506004385\n",
      "0.48183956101384895\n",
      "0.5\n",
      "0.4935701163502756\n",
      "0.5117184630078613\n",
      "0.5229254433232096\n",
      "0.48225195204024957\n",
      "0.4748756645515349\n",
      "0.5006043973994576\n",
      "0.5145068488672399\n",
      "0.49666964336919034\n",
      "0.4864366239724406\n",
      "0.5196749148917064\n",
      "0.5295337972491752\n",
      "0.5081209150326798\n",
      "0.5006082079499719\n",
      "0.47225309751871586\n",
      "0.4927450980392156\n",
      "0.5354842396584238\n",
      "0.5053704067275285\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5062942720395623"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aucs = []\n",
    "for i in range(y.shape[1]):\n",
    "    fpr, tpr, thresholds = roc_curve(y_train[:,i], y_pred[:,i],)\n",
    "    aucs.append(auc(fpr,tpr))\n",
    "    print(aucs[i])\n",
    "np.mean(aucs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5062942720395623"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "musictagger",
   "language": "python",
   "name": "musictagger"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

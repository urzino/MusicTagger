{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.io import wavfile\n",
    "\n",
    "from sklearn.metrics import accuracy_score, hamming_loss, zero_one_loss, auc\n",
    "\n",
    "from bokeh.plotting import figure, show\n",
    "from bokeh.io import output_notebook\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "import librosa\n",
    "import pickle as pk\n",
    "\n",
    "from keras.layers import Conv2D, MaxPool2D, Activation, Dense, Input, Flatten, BatchNormalization, Dropout\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import Sequence\n",
    "import keras.backend as K\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "dataset_dir = '../data/MagnaTagATune/MEL_default_hop/'\n",
    "annotations_path = '../data/MagnaTagATune/annotation_reduced_50.csv'\n",
    "\n",
    "checkpoint_dir = './checkpoints_RAW/'\n",
    "checkpoint_file_name = 'weights-{epoch:03d}-{val_loss:.5f}.hdf5'\n",
    "log_dir ='./logs_MEL_32f/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Align dataset split to batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_split(split, batch_size, num_songs):\n",
    "    num_songs_split = split*num_songs\n",
    "    return int(num_songs_split - num_songs_split%batch_size)/num_songs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Data reading during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MagnaTagATuneSequence(Sequence):\n",
    "\n",
    "    def __init__(self, train_set_paths, train_set_labels, batch_size):\n",
    "        self.paths, self.y = train_set_paths, train_set_labels\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.paths) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x_paths = self.paths[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_x = []\n",
    "        for value in batch_x_paths:\n",
    "            path = dataset_dir + value[:-3]+'p'\n",
    "            S = pk.load(open(path,'rb'))\n",
    "            batch_x.append(S)\n",
    "        batch_x = np.array(batch_x)[:,:,:,np.newaxis]        \n",
    "        return (batch_x,batch_y)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Performance Metrics (not used anymore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ratio_wrong_over_correct_ones(y_true, y_pred):\n",
    "    op1 = K.sum(K.abs(K.cast(y_true - K.round(y_pred), dtype='float32')))\n",
    "    op2 = K.sum(K.cast(K.equal(y_true,1.0),dtype='float32'))\n",
    "    return op1/op2\n",
    "\n",
    "def ratio_correct_ones(y_true, y_pred):\n",
    "    op1 = K.sum(K.cast(K.equal(y_true + K.round(y_pred+0.15),2.0),dtype='float32'))\n",
    "    op2 = K.sum(K.cast(K.equal(y_true,1.0),dtype='float32'))\n",
    "    return op1/op2\n",
    "\n",
    "def auc_roc(y_true, y_pred):\n",
    "    # any tensorflow metric\n",
    "    value, update_op = tf.metrics.auc(y_true, y_pred, summation_method='careful_interpolation')\n",
    "\n",
    "    # find all variables created for this metric\n",
    "    metric_vars = [i for i in tf.local_variables() if 'auc_roc' in i.name.split('/')[1]]\n",
    "\n",
    "    # Add metric variables to GLOBAL_VARIABLES collection.\n",
    "    # They will be initialized for new session.\n",
    "    for v in metric_vars:\n",
    "        tf.add_to_collection(tf.GraphKeys.GLOBAL_VARIABLES, v)\n",
    "\n",
    "    # force to update metric values\n",
    "    with tf.control_dependencies([update_op]):\n",
    "        value = tf.identity(value)\n",
    "        return value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Best checkpoint selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_checkpoint(prev_chkpts):\n",
    "    best_ratio = np.inf\n",
    "    best_chkpt = ''\n",
    "    best_epoch = 0\n",
    "    for chkpt in prev_chkpts:\n",
    "        epoch = int(chkpt[8:11])\n",
    "        ratio = float(chkpt[12:19])\n",
    "        \n",
    "        if ratio < best_ratio:\n",
    "            best_ratio = ratio\n",
    "            best_chkpt = chkpt\n",
    "            best_epoch = epoch\n",
    "    print('\\n starting from model {} \\n'.format(best_chkpt))\n",
    "    return best_chkpt, best_epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete Train set size: 22400\n",
      "Test set size: 3460 \n",
      "\n",
      "Train set size: 20480\n",
      "Validation set size: 1920 \n",
      "\n",
      "X dimension: (128, 911)\n",
      "Y dimension: 50 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"   \\nval_set_paths = val_set['mp3_path'].values\\nval_set_labels = val_set.drop(columns=['mp3_path','Unnamed: 0']).values\\n    \\n\\n    \\nprint('\\n* * * Loading Validation Set into Memory * * *\\n')\\n\\nval_set_data = []\\nfor value in tqdm(val_set_paths):\\n    path = dataset_dir+value[:-3]+'p'\\n    S = pk.load(open(path,'rb'))\\n    val_set_data.append(S)  \\nval_set_data = np.array(val_set_data)[:,:,:,np.newaxis] \\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations = pd.read_csv(annotations_path, sep='\\t')\n",
    "\n",
    "tot_t_size = 0.866203\n",
    "tot_train_set, test_set = train_test_split(annotations, train_size=tot_t_size, test_size=(1-tot_t_size), random_state=42) \n",
    "\n",
    "print(\"Complete Train set size: {}\".format(tot_train_set.shape[0]))\n",
    "print(\"Test set size: {} \\n\".format(test_set.shape[0]))\n",
    "\n",
    "t_size = 0.91429\n",
    "train_set, val_set = train_test_split(tot_train_set, train_size=t_size, test_size=(1-t_size), random_state=42) \n",
    "\n",
    "print(\"Train set size: {}\".format(train_set.shape[0]))\n",
    "print(\"Validation set size: {} \\n\".format(val_set.shape[0]))\n",
    "\n",
    "train_set_paths = train_set['mp3_path'].values\n",
    "train_set_labels = train_set.drop(columns=['mp3_path','Unnamed: 0']).values\n",
    "\n",
    "y_dimension = train_set_labels.shape[1]\n",
    "S = pk.load(open(dataset_dir + annotations['mp3_path'][0][:-3]+ 'p','rb'))\n",
    "x_dimension = S.shape\n",
    "\n",
    "print(\"X dimension: {}\\nY dimension: {} \\n\".format(x_dimension, y_dimension))\n",
    "\n",
    "'''   \n",
    "val_set_paths = val_set['mp3_path'].values\n",
    "val_set_labels = val_set.drop(columns=['mp3_path','Unnamed: 0']).values\n",
    "    \n",
    "\n",
    "    \n",
    "print('\\n* * * Loading Validation Set into Memory * * *\\n')\n",
    "\n",
    "val_set_data = []\n",
    "for value in tqdm(val_set_paths):\n",
    "    path = dataset_dir+value[:-3]+'p'\n",
    "    S = pk.load(open(path,'rb'))\n",
    "    val_set_data.append(S)  \n",
    "val_set_data = np.array(val_set_data)[:,:,:,np.newaxis] \n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Prepare Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set size: 3460 \n"
     ]
    }
   ],
   "source": [
    "test_set_paths = test_set['mp3_path'].values\n",
    "test_set_labels = test_set.drop(columns=['mp3_path','Unnamed: 0']).values\n",
    "test_set_size = len(test_set_paths)\n",
    "print(\"Test set size: {} \".format(test_set_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Load best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './checkpoints_MEL_32f/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-3e513953f2fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprevious_checkpoints\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mbest_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_best_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprevious_checkpoints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#model.load_weights(checkpoint_dir + best_checkpoint)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './checkpoints_MEL_32f/'"
     ]
    }
   ],
   "source": [
    "n_gpus = 1\n",
    "batch_size = 32\n",
    "\n",
    "previous_checkpoints = os.listdir(checkpoint_dir)\n",
    "best_checkpoint, best_epoch = find_best_checkpoint(previous_checkpoints)\n",
    "#model.load_weights(checkpoint_dir + best_checkpoint)\n",
    "model = keras.models.load_model(checkpoint_dir + best_checkpoint)\n",
    "parallel_model = keras.utils.multi_gpu_model(model, gpus=n_gpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Prediction and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109/109 [==============================] - 491s 5s/step\n"
     ]
    }
   ],
   "source": [
    "predictions = parallel_model.predict_generator(MagnaTagATuneSequence(test_set_paths, test_set_labels, batch_size), verbose=1)\n",
    "#predictions = parallel_model.predict(test_set_data,batch_size=batch_size,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test roc auc result: 0.8932105996027028 \n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    roc_auc = roc_auc_score(test_set_labels, predictions)\n",
    "    print(\"Test roc auc result: {} \".format(roc_auc))\n",
    "except Error as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emanuele.dallalonga/miniconda3/envs/musictagger/lib/python3.6/site-packages/ipykernel_launcher.py:10: RuntimeWarning: invalid value encountered in true_divide\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Singleton array 0.0 cannot be considered a valid collection.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-7e9f187ab1bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mratio\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mfpr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mbest_th\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthresholds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mratio\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mbest_auc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mratio\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtpr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mratio\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mroc_auc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/musictagger/lib/python3.6/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36mauc\u001b[0;34m(x, y, reorder)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mCompute\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mrecall\u001b[0m \u001b[0mpairs\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdifferent\u001b[0m \u001b[0mprobability\u001b[0m \u001b[0mthresholds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \"\"\"\n\u001b[0;32m---> 78\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/musictagger/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \"\"\"\n\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m     \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/musictagger/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \"\"\"\n\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m     \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/musictagger/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_num_samples\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             raise TypeError(\"Singleton array %r cannot be considered\"\n\u001b[0;32m--> 119\u001b[0;31m                             \" a valid collection.\" % x)\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Singleton array 0.0 cannot be considered a valid collection."
     ]
    }
   ],
   "source": [
    "fpr = dict()\n",
    "tpr = dict()\n",
    "thresholds = dict()\n",
    "ratio = dict()\n",
    "roc_auc = dict()\n",
    "best_th = dict()\n",
    "beast_auc = dict()\n",
    "for i in range(test_set_labels.shape[1]):\n",
    "    fpr[i], tpr[i], thresholds[i] = roc_curve(test_set_labels[:, i], predictions[:, i])\n",
    "    ratio[i] = tpr[i]/fpr[i]\n",
    "    best_th[i] = thresholds[i][np.argmax(ratio[i])]\n",
    "    best_auc[i] = auc(fpr[i][np.argmax(ratio[i])],tpr[i][np.argmax(ratio[i])])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    \n",
    "    \n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(test_set_labels.ravel(), predictions.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "lw = 3\n",
    "label = 2\n",
    "plt.plot(fpr[label], tpr[label], color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc[label])\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "print(best_th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = predictions[0]\n",
    "print(\"All the same: {}\".format(all([all(i) for i in [test-i<np.finfo(np.float32).eps for i in predictions]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=501\n",
    "print(predictions[a])\n",
    "print(test_set_labels[a])\n",
    "\n",
    "d = dict()\n",
    "for idx in range(y_dimension):\n",
    "    \n",
    "K.eval(ratio_correct_ones(y_true=K.variable(test_set_labels), y_pred=K.variable(predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "weights = np.concatenate([ i.flatten() for i in model.get_weights() ])\n",
    "print('Are there NaN weights? {}'.format(any([ math.isnan(i) for i in weights])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
